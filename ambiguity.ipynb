{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rejection.ambiguity.ambiguity import ambiguity_rejection\n",
    "import pickle\n",
    "folder_path = 'output/'\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import loglaplace,chi2\n",
    "from labellines import *\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rr, detail_factor, train_forest_model_list, xt_list, all_data_list, file_path, experiment_id, dataset, rmse_accepted_perfect = \n",
    "\n",
    "metrics_results = {'TWINSC': {}, 'IHDP': {}}\n",
    "\n",
    "reject_rates_list = {'TWINSC': {}, 'IHDP': {}}\n",
    "\n",
    "heuristic_cutoff_list = {'TWINSC': {}, 'IHDP': {}}\n",
    "\n",
    "metrics_results_list_global = {'TWINSC': {}, 'IHDP': {}}\n",
    "\n",
    "experiment_ids_list = {'TWINSC': {}, 'IHDP': {}}\n",
    "\n",
    "# Graph: RMSE vs Reject Rate\n",
    "twinsc_rmse = {}\n",
    "twinsc_rmse_change = {}\n",
    "twinsc_reject_rates = {} \n",
    "ihdp_reject_rates = {}\n",
    "ihdp_rmse = {}\n",
    "ihdp_rmse_change = {}\n",
    "\n",
    "# i = -1 # (dataset 0 first)\n",
    "for dataset in ['TWINSC', 'IHDP']:\n",
    "\n",
    "    # Define the file path where the data is saved\n",
    "    file_path = f'{folder_path}overleaf/data/{dataset}/ambiguity.pkl'\n",
    "\n",
    "    # Load the data from the file using pickle\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data_loaded = pickle.load(f)\n",
    "\n",
    "    # Now you can access the dictionaries in the list data_loaded\n",
    "    max_rr, detail_factor, train_forest_model_list, xt_list, all_data_list, file_path, experiment_id, dataset, rmse_accepted_perfect = data_loaded\n",
    "\n",
    "    metrics_dict, reject_rates, heuristic_cutoff, metrics_results_list = ambiguity_rejection(max_rr, detail_factor, train_forest_model_list, xt_list, all_data_list, file_path, experiment_id, dataset, rmse_accepted_perfect)\n",
    "\n",
    "    experiment_id = 1\n",
    "    metrics_results[dataset].update({experiment_id: reject_rates})\n",
    "    # reject_rates_list[dataset].update({experiment_id: reject_rates})\n",
    "    # heuristic_cutoff_list[dataset].update({experiment_id: heuristic_cutoff})\n",
    "    # metrics_results_list_global[dataset].update({experiment_id: metrics_results_list})\n",
    "    # experiment_ids_list[dataset].update({experiment_id: experiment_id})\n",
    "\n",
    "# Define the data for TWINSC dataset\n",
    "for experiment_id, reject_rates in reject_rates_list['TWINSC'].items():\n",
    "    twinsc_reject_rates[experiment_id] = reject_rates\n",
    "\n",
    "for i in range(1, len(reject_rates_list['TWINSC']) + 1):  # Adjusting range to start from 1\n",
    "    twinsc_rmse[i] = [result.get('RMSE Accepted', None) for result in metrics_results_list_global.get('TWINSC', {}).get(i, {})]\n",
    "    twinsc_rmse_change[i] = [result.get('RMSE Change', None) for result in metrics_results_list_global.get('TWINSC', {}).get(i, {})]\n",
    "\n",
    "print(twinsc_reject_rates[1])\n",
    "print(twinsc_rmse[1])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
